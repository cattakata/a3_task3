---
title: "Assignment 3, Task 3: East of Eden text analysis"
author: "Catherine Takata"
date: "2/25/2021"
output: 
  html_document:
    theme: cerulean
    code_folding: show
    toc: true
---

## Summmary 
In this task, we will explore text wrangling and analysis of East of Eden by John Steinbeck. We will tidy and tokenize a pdf and further determine the most used words as well as the sentiment ranking via the 'AFINN' lexicon. 

Sources: Julia Silge and David Robinson (https://www.tidytextmining.com/sentiment.html), Steinbeck, East of Eden, Internet Archive (text).  


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(tidytext)
library(textdata)
library(pdftools)
library(ggwordcloud)
```

```{r, cache=TRUE}
eden_text <- pdf_text("east_of_eden.pdf")
```

```{r, warning=F, message=F}
eden_tidy <- data.frame(eden_text) %>% 
  mutate(text_full = str_split(eden_text, pattern = '\\n')) %>% 
  unnest(text_full) %>% 
  mutate(text_full = str_trim(text_full)) 
```

```{r, warning=F, message=F}
# Use mutate() to create a new column of data
# Conditional entry using case_when() if we detect a string "Chapter"
# Set NA to the right column class: "character" so it the column will be populated if CHAPTER is not detected 

eden_df <- eden_tidy %>% 
  slice(-(1:105)) %>% 
  mutate(chapter = case_when(
    str_detect(text_full, "CHAPTER") ~ text_full,
    TRUE ~ NA_character_
  )) %>% 
  fill(chapter) %>% 
  separate(col = chapter, into = c("ch", "no"), sep = " ") %>% 
  mutate(chapter = as.numeric(no))
```

## Wrangle data

### Token-ized text format 

```{r, warning=F, message=F}
# Break up text into individual tokens of individual words in a new column 
eden_tokens <- eden_df %>% 
  unnest_tokens(word, text_full) %>% 
  select(-eden_text)

eden_wordcount <- eden_tokens %>% 
  count(chapter, word)
```

### Stop words 
We will *remove* stop words using `tidyr::anti_join()`, which will *omit* any words in `stop_words` from `eden_tokens`.

```{r, warning=F, message=F}
# What do we NOT want to keep 
eden_nonstop_words <- eden_tokens %>% 
  anti_join(stop_words)

# Counts 
nonstop_counts <- eden_nonstop_words %>% 
  count(chapter, word)
```

## Word cloud data visualization

```{r, warning=F, message=F}
ch1_top100 <- nonstop_counts %>% 
  filter(chapter == 1) %>% 
  arrange(-n) %>% 
  slice(1:100)

ggplot(data = ch1_top100, aes(label = word)) +
  geom_text_wordcloud(aes(color = n, size = n), shape = "diamond") +
  scale_size_area(max_size = 6) +
  scale_color_gradientn(colors = c("slateblue","green","purple")) +
  theme_minimal() +
  labs(title = "Top 100 most used words", 
       subtitle = "Chapter 1, East of Eden by John Steinbeck")
```


## Sentiment analysis with East of Eden

```{r}
# Use interjoin() to keep words in East of Eden that can be evaluated in the 'afinn' lexicon 
eden_afinn <- eden_nonstop_words %>% 
  inner_join(get_sentiments("afinn"))

# Find the mean by sentiment analysis ranking 
afinn_means <- eden_afinn %>% 
  group_by(chapter) %>% 
  summarize(mean_afinn = mean(value))

ggplot(data = afinn_means, 
       aes(x = fct_rev(as.factor(chapter)), 
           y = mean_afinn)) +
  geom_col(fill = "slateblue") +
  coord_flip() +
  theme_minimal() +
  labs(title = "Mean score by AFINN sentiment analysis ranking", 
       subtitle = "By chapter, East of Eden by John Steinbeck",
       x = "Chapters",
       y = "Mean Score")
```















